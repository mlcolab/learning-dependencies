\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
\usepackage[preprint]{neurips_2021}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[colorlinks = true, 
		    linkcolor = blue,
		    urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}       
% hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{natbib}
\usepackage[pdftex]{graphicx}
\usepackage{siunitx} % Required for alignment
\sisetup{
  round-mode          = places, % Rounds numbers
  round-precision     = 2, % to 2 places
}
	
\bibliographystyle{unsrtnat}


\title{Extracting and evaluating educational concept dependencies implicit in Large Language Models}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Dominik Glandorf\\
  Matrikelnummer 6007407\\
  \texttt{dominik.glandorf@student.uni-tuebingen.de} \\
  \And
  Anastasiia Alekseeva\\
  Matrikelnummer 5994775\\
  \texttt{anastasiia.alekseeva@student.uni-tuebingen.de} \\
  \\
  GitHub repository: \url{https://github.com/mlcolab/learning-dependencies}
}

\begin{document}
\vspace*{-5mm}
\maketitle
\vspace*{-5mm}

\begin{abstract}
% What did we do?

% Why did we to it? What did we expect?

% How did we do it?

% What did we find out?

% What now?

\end{abstract}

\section{Introduction}
% What is the field where we contributed
Large Language Models are trained on immense corpora of text and have proven to capture included factual information by building on it when performing well in downstream tasks such as question answering. This observation led to the research line of Knowledge Extraction from LLMs (Cohen, 2023). In this work, we focus on the extraction of educational knowledge that is implicitly captured in LLMs and poses a subfield that has rather stagnated in the previous years.

% Why are we interested in concept dependencies?
%% Problem of sequencing in Instructional Design:
Effective and efficient instruction does not only incorporate what to teach but also how to teach. Guidelines for \textit{instructional sequencing} emphasize the order of instruction. More precisely, prerequisites of educational content should be either known to the student or taught first \citep{morrison2019designing}.
% Definition concepts
Within educational content, Merill (1983) differentiated facts, concepts, principles, rules, procedures, interpersonal skills, attitudes, and their sole recall from their application. To simplify, we will focus on concepts and their relations. 
% Concept dependency
% Assumption: information about dependencies between concepts makes instructional sequencing more effective in terms of learning
If one concept is a prerequisite of another, we call this relation a concept dependency. For example, to understand the concept of a derivative, having knowledge about the concept of a function will facilitate or even enable learning. When the dependencies are thought of as directed edges between nodes that represent concepts, a concept dependency graph emerges which is a special type of a knowledge graph \citep{wang2016using}. This graph is also called \textit{concept map} in the field of Learning Sciences.

% Approaches: Automatic extraction of concept dependencies
Prerequisites can be inferred from learner behavior by testing their performance after being presented different instructional sequences (Pavlik et al., 2008, Vuong et al., 2011). However, this has the disadvantage of disengaging users with too difficult concepts before teaching easier or necessary ones. Experts usually dispose of the required knowledge about concepts to create concept maps. The high cost of expert knowledge motivates the automated extraction of concept dependencies from appropriate sources.

% What is our research question?
% How to extract educational concept dependencies that are implicit and evaluate them using existing knowledge media?

% What can we contribute?
% 1. No benchmark available -> we set up an evaluation framework based on textbooks and Wikipedia
% 2. Emerging field of prompt engineering -> we engineered a simple but effective prompt process to query a LLM




\subsection{Related work}
% Field: Dependencies between concepts
% of interest: How are dependencies conceptualized?
\cite{talukdar2012crowdsourced} defined the prerequisite relation in terms of the consumption of information about concepts. Vuong (2011) if a better graduation rate given prerequisite knowledge is fulfilled. Concepts are often equated with Wikipedia articles (Talukdar and Cohen, 2012; Wang, 2015).
% Field: Textbook Knowledge Extraction
% of interest: How are relationships betweens concepts extracted?
% Field: Prompt Engineering
% of interest: How can we get internal representations out of a language model?

\section{Method}

\subsection{Information sources}
% Where did we get the data from?
% textbooks
For preprocessing the textbooks we used Wikifier \citep{brank2017annotating}.
% language models

\subsection{Structured information extraction}
% Data quality

% Visualizations

% Statistics

\section{Results}



\section{Discussion}
% What is our main result?

% What could be potential flaws?

% Q: Outlook and Future research ideas:% 


\bibliography{references.bib}

\end{document}

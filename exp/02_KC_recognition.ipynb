{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize KCs of interest in book text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "f = open(\"../dat/parsed_books/mml-book.txt\", \"r\")\n",
    "raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the Wikifier (https://wikifier.org) to recognize and link entities to their corresponding Wikipedia page. Then we might need to filter for KCs that are of relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\"../.env\")\n",
    "userKey = config['WIKIFIER_USER_KEY']\n",
    "\n",
    "response = requests.post(\"http://www.wikifier.org/annotate-article\",\n",
    "    data={\"userKey\": userKey,\n",
    "          \"lang\": \"en\",\n",
    "          \"text\": raw_text[:1000],\n",
    "          \"support\": \"true\",\n",
    "          \"ranges\": \"true\"},\n",
    ")\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATHEMATICS  FOR \n",
      "MACHINE LEARNING\n",
      "Marc Peter DeisenrothA. Aldo FaisalCheng Soon Ong\n",
      "MATHEMATICS FOR MACHINE LEARNING DEISENROTH ET AL.\n",
      "The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efï¬  ciently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "supports = {\n",
    "    a['title']: \n",
    "        {\"url\": a['url'],\n",
    "         \"occurences\": [\n",
    "            {\"intvl\": pd.Interval(s['chFrom'], s['chTo']), \"pr\": s['pageRank']}\n",
    "        for s in a['support'] if s['pageRank'] > 0.001] \n",
    "    } \n",
    "    for a in response['annotations']\n",
    "}\n",
    "\n",
    "supports = {k: v for k, v in supports.items() if len(v['occurences'])>0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to clean overlaps such as mixture model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "KCs_cleaned = []\n",
    "for title, value in supports.items():\n",
    "    occs_cleaned = []\n",
    "    for idx, occ in enumerate(value['occurences']):\n",
    "        # detect overlaps\n",
    "        current_intvl = occ['intvl']\n",
    "        overlaps = [o for o in value['occurences'] if o['intvl'].overlaps(current_intvl) and occ['intvl'] != o['intvl']]\n",
    "        if len(overlaps): # if we have overlaps, only take the one with the highest Page Rank\n",
    "            if np.all([occ['pr'] > o['pr'] for o in overlaps]): occs_cleaned.append(occ)\n",
    "        else:\n",
    "            occs_cleaned.append(occ)\n",
    "\n",
    "    KCs_cleaned.append({\"title\": title, \"url\": value['url'], \"occurences\": occs_cleaned})\n",
    "\n",
    "\n",
    "pickle.dump(KCs_cleaned, open(\"../dat/KCs.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upscaling to more than first 1000 characters. First some performance tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859742\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(text):\n",
    "    try:\n",
    "        response = requests.post(\"http://www.wikifier.org/annotate-article\",\n",
    "            data={\"userKey\": userKey,\n",
    "                \"lang\": \"en\",\n",
    "                \"text\": text,\n",
    "                \"support\": \"true\",\n",
    "                \"ranges\": \"true\"},\n",
    "        )\n",
    "        response = response.json()\n",
    "        return response['annotations']\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468075\n",
      "670469\n",
      "354203\n",
      "165199\n"
     ]
    }
   ],
   "source": [
    "lengths = [1000, 2000, 4000, 8000]\n",
    "execution_times = []\n",
    "import time\n",
    "import random\n",
    "\n",
    "for l in lengths:\n",
    "    # select random text of length l\n",
    "    start_pos = int(random.random() * (len(raw_text)-l))\n",
    "    print(start_pos)\n",
    "    # call Wikifier\n",
    "    start_time = time.time()\n",
    "    get_annotations(raw_text[start_pos:(start_pos+l)])\n",
    "    execution_times.append(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.279824256896973, 8.296481132507324, 10.221187829971313, 43.09164214134216]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a length around 5000 characters has the best time-length-ratio. Let's try to get KCs for the first 100000 characters of the book (about one eigth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "batch_num = 20\n",
    "start = 0\n",
    "\n",
    "KCs = {}\n",
    "for i in range(batch_num):\n",
    "    print('Batch ' + str(i))\n",
    "    offset = start + i * batch_size\n",
    "    #print(raw_text[offset:(offset+batch_size)])\n",
    "    annotations = get_annotations(raw_text[offset:(offset+batch_size)])\n",
    "    supports = {\n",
    "        a['title']: \n",
    "            {\"url\": a['url'],\n",
    "            \"occurences\": [\n",
    "                {\"intvl\": pd.Interval(s['chFrom'] + offset, s['chTo'] + offset), \"pr\": s['pageRank']}\n",
    "            for s in a['support'] if s['pageRank'] > 0.001]}\n",
    "        for a in annotations\n",
    "    }\n",
    "\n",
    "    # offset characters and merge with existing supports\n",
    "    for title, value in supports.items():\n",
    "        if len(value['occurences']) > 0: # only for supports with a good page rank\n",
    "            if not title in KCs: # ensure that KC exists\n",
    "                KCs[title] = {'url': value['url'], 'occurences': []}\n",
    "\n",
    "            occs = []\n",
    "            for idx, occ in enumerate(value['occurences']):\n",
    "                # detect overlaps\n",
    "                current_intvl = occ['intvl']\n",
    "                overlaps = [o for o in value['occurences'] if o['intvl'].overlaps(current_intvl) and occ['intvl'] != o['intvl']]\n",
    "                if len(overlaps): # if we have overlaps, only take the one with the highest Page Rank\n",
    "                    if np.all([occ['pr'] > o['pr'] for o in overlaps]): occs.append(occ)\n",
    "                else:\n",
    "                    occs.append(occ)\n",
    "\n",
    "            KCs[title]['occurences'] = KCs[title]['occurences'] + occs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save KCs\n",
    "pickle.dump(KCs, open(\"../dat/KCs_mml.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine learning': 91,\n",
       " 'Linear algebra': 14,\n",
       " 'Linear regression': 7,\n",
       " 'Analytic geometry': 3,\n",
       " 'Matrix decomposition': 3,\n",
       " 'Vector calculus': 5,\n",
       " 'Computer science': 4,\n",
       " 'Principal component analysis': 5,\n",
       " 'Mixture model': 3,\n",
       " 'Support-vector machine': 5,\n",
       " 'Linear independence': 28,\n",
       " 'Mathematics': 11,\n",
       " 'Euclidean vector': 13,\n",
       " 'Real number': 3,\n",
       " 'Complex number': 4,\n",
       " 'Vector space': 40,\n",
       " 'Dot product': 4,\n",
       " 'Identity matrix': 5,\n",
       " 'Kernel (linear algebra)': 3,\n",
       " 'Subscript and superscript': 13,\n",
       " 'Random variable': 3,\n",
       " 'Dimensionality reduction': 7,\n",
       " 'Tor (rock formation)': 3,\n",
       " 'System of linear equations': 44,\n",
       " 'Free variables and bound variables': 4,\n",
       " 'Matrix (mathematics)': 5,\n",
       " 'Row and column vectors': 3,\n",
       " 'Fraction': 48,\n",
       " 'Matrix multiplication': 11,\n",
       " 'Gaussian elimination': 11,\n",
       " 'Augmented matrix': 7,\n",
       " 'AJB': 3,\n",
       " 'Row echelon form': 13,\n",
       " 'Pivot element': 15,\n",
       " 'Iterative method': 3,\n",
       " 'Inverse element': 10,\n",
       " 'Identity element': 10,\n",
       " 'Abelian group': 4,\n",
       " 'General linear group': 3,\n",
       " 'Kigali': 5,\n",
       " 'Dimension (vector space)': 3,\n",
       " 'Bijection': 6}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{title: len(v['occurences']) for title, v in KCs.items() if len(v['occurences']) > 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with TFIDF output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\"\"\n",
    "Introduction and Motivation: \n",
    "  learning, data, machine, machine learning, model, book, pillar, vector, concept, chapter, part, mathematical concept, foundation, mathematical, unseen, predictor, label, read, training, two, regression, way, learning system, machine learning system, read book, part ii, way read book, way read, pillar machine, two way read, four pillar machine, four pillar, pillar machine learning, data vector, unseen data, parameter, nd, well, input, density, system, algorithm, mean, estimation, two way, motivation, ing, classi cation, machine learning algorithm, goal\n",
    "Linear Algebra: \n",
    "  vector, linear, matrix, column, basis, space, equation, mapping, subspace, system linear, pivot, system linear equation, linear equation, system, vector space, de, row, linearly, set, coordinate, solution, pivot column, linear mapping, ne, element, rn, linear algebra, transformation, respect, echelon form, echelon, algebra, form, row echelon form, row echelon, af, af ne, transformation matrix, group, inverse, following, example, two, consider, rm, linearly independent, base, equation system, multiplication, combination\n",
    "Analytic Geometry: \n",
    "  projection, vector, product, inner, inner product, orthogonal, basis, subspace, rotation, de, angle, space, hx, norm, matrix, dimensional, onto, orthogonal projection, distance, figure, co, nite, basis vector, projection onto, positive, length, projection matrix, hx yi, yi, de nite, vector space, dot, positive de, sin, two, dot product, product inner product, positive de nite, dimensional subspace, linear, span, orthonormal, de nition, nition, rotate, symmetric, product inner, chapter, dot product inner, analytic geometry\n",
    "Matrix Decompositions: \n",
    "  matrix, svd, eigenvalue, eigenvectors, singular, decomposition, vector, singular value, movie, determinant, det, basis, rank, value, rn, singular vector, eigendecomposition, diagonal, theorem, right singular, mapping, de, spectral, square, rank approximation, right, matrix decomposition, column, cholesky, right singular vector, approximation, linear, trace, det det, orthogonal, section, eigenvector, characteristic, square matrix, tr, left, linear mapping, figure, diagonal matrix, rating, eigenvalue eigenvectors, change, positive, matrix rn, ba\n",
    "Vector Calculus: \n",
    "  derivative, partial, function, taylor, gradient, partial derivative, rule, chain rule, chain, taylor series, vector, series, fk, df, jacobian, differentiation, compute, matrix, de, fi, respect, tensor, xn, dx, fk fk, series expansion, order, polynomial, taylor series expansion, exp, rn, fk fk fk, expansion, yf, taylor polynomial, compute gradient, automatic differentiation, xf, sin, vector calculus, figure, automatic, obtain, variable, section, fm, compute derivative, linear, calculus, df dx\n",
    "Probability and Distributions: \n",
    "  random, random variable, distribution, variable, probability, covariance, variance, gaussian, prior, statistic, mean, discrete, function, de, exponential, family, exponential family, section, two, cov, beta, example, event, rule, space, density, probability distribution, marginal, sample, value, conditional, bernoulli, continuous random, consider, gaussian distribution, posterior, continuous, theorem, continuous random variable, univariate, cdf, xjy, outcome, multivariate, de nition, nition, state, two random, sum, covariance matrix\n",
    "Continuous Optimization: \n",
    "  convex, function, gradient, optimization, descent, gradient descent, convex function, min, optimization problem, dual, problem, minimum, convex set, convex optimization, set, constraint, function convex, legendre, convex conjugate, continuous optimization, multiplier, lagrange, lagrangian, duality, subject, de, differentiable, max, step size, point, value, two, conjugate, consider, objective function, lagrange multiplier, step, constrained, primal, negative, inequality, size, objective, linear program, example, program, line, figure, legendre fenchel, momentum\n",
    "\"\"\"\n",
    "\n",
    "annos = get_annotations(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = {\n",
    "    a['title']: \n",
    "        {\"url\": a['url'],\n",
    "        \"occurences\": [\n",
    "            {\"intvl\": pd.Interval(s['chFrom'] + offset, s['chTo'] + offset), \"pr\": s['pageRank']}\n",
    "        for s in a['support'] if s['pageRank'] > 0.0005]}\n",
    "    for a in annos\n",
    "}\n",
    "\n",
    "KCs_from_tfidf = {}\n",
    "# offset characters and merge with existing supports\n",
    "for title, value in supports.items():\n",
    "    if len(value['occurences']) > 0: # only for supports with a good page rank\n",
    "        if not title in KCs_from_tfidf: # ensure that KC exists\n",
    "            KCs_from_tfidf[title] = {'url': value['url'], 'occurences': []}\n",
    "\n",
    "        occs = []\n",
    "        for idx, occ in enumerate(value['occurences']):\n",
    "            # detect overlaps\n",
    "            current_intvl = occ['intvl']\n",
    "            overlaps = [o for o in value['occurences'] if o['intvl'].overlaps(current_intvl) and occ['intvl'] != o['intvl']]\n",
    "            if len(overlaps): # if we have overlaps, only take the one with the highest Page Rank\n",
    "                if np.all([occ['pr'] > o['pr'] for o in overlaps]): occs.append(occ)\n",
    "            else:\n",
    "                occs.append(occ)\n",
    "\n",
    "        KCs_from_tfidf[title]['occurences'] = KCs_from_tfidf[title]['occurences'] + occs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine learning': 4,\n",
       " 'Vector space': 2,\n",
       " 'Vector calculus': 1,\n",
       " 'Ion': 1,\n",
       " 'Linear algebra': 1,\n",
       " 'Linear equation': 2,\n",
       " 'Linear map': 2,\n",
       " 'Linear programming': 1,\n",
       " 'Matrix (mathematics)': 1,\n",
       " 'Eigenvalues and eigenvectors': 5,\n",
       " 'Analytic geometry': 1,\n",
       " 'Eigendecomposition of a matrix': 1,\n",
       " 'Row echelon form': 1,\n",
       " 'Transformation matrix': 1,\n",
       " 'Linear independence': 1,\n",
       " 'Projection (linear algebra)': 2,\n",
       " 'Dot product': 4,\n",
       " 'Orthonormality': 1,\n",
       " 'Matrix decomposition': 1,\n",
       " 'Singular value decomposition': 1,\n",
       " 'Diagonal matrix': 1,\n",
       " 'Partial derivative': 1,\n",
       " 'Gradient descent': 1,\n",
       " 'Chain rule': 1,\n",
       " 'Automatic differentiation': 1,\n",
       " 'Random variable': 2,\n",
       " 'Probability distribution': 2,\n",
       " 'Normal distribution': 1,\n",
       " 'Covariance matrix': 1,\n",
       " 'Exponential family': 1,\n",
       " 'Continuous optimization': 1,\n",
       " 'Mathematical optimization': 2,\n",
       " 'Convex set': 1,\n",
       " 'Convex function': 1,\n",
       " 'Convex optimization': 1,\n",
       " 'Convex conjugate': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{title: len(v['occurences']) for title, v in KCs_from_tfidf.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('LD-inference')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b3dd287303ef379cd3bfc1446cef400144e42385eabfb9b315f60147448249f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
